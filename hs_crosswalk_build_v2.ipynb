{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "We have previously extracted and cleaned a dataset of high school (HS) data from students who have submitted applications to CU Boulder This data includes the HS name, its CEEB code, as well as some location information (ZIP, City, and State). The product of this notebook will be a table of HS names, CEEB, and NCES codes, as well as some additional location data where available. This \"crosswalk\" can then be used to build a more complete HS dataset.\n",
    "\n",
    "# Script\n",
    "Begin with some imports and preliminaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/Desktop/ODA/ceeb_nces_crosswalk/venv/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import os.path as path\n",
    "import pickle as p\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "np.random.seed(8675309)\n",
    "\n",
    "# useful directories\n",
    "PROJ_DIR = path.abspath('/home/peter/Desktop/ODA/ceeb_nces_crosswalk')\n",
    "DATA_DIR = path.join(PROJ_DIR,'data')\n",
    "MTURK_DIR = path.join(PROJ_DIR,'mturk')\n",
    "\n",
    "# read in the data\n",
    "hs_df = pd.read_csv(path.join(DATA_DIR,'ucb_apps_hs.csv'),dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging with the Davenport Crosswalk\n",
    "Let's now load the Davenport CEEB-NCES crosswalk ([source](https://ire.uncg.edu/research/NCES_CEEB_Table/)). We'll use this as the base, and drop all records in our dataset which can be found in the Davenport data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the CEEB-NCES crosswalk database TEST\n",
    "davenport_cross = pd.read_excel(path.join(DATA_DIR,'davenport_nces_ceeb_crosswalk.xlsx'),\n",
    "                               dtype=str)\n",
    "\n",
    "# Davenport provided multiple columns for the same items, condense those down\n",
    "davenport_cross.HS_CITY.fillna(davenport_cross.SAS_MATCH_CITY, inplace=True)\n",
    "davenport_cross.HS_STATE.fillna(davenport_cross.SAS_MATCH_STATE, inplace=True)\n",
    "davenport_cross.HS_ZIP.fillna(davenport_cross.SAS_MATCH_ZIP, inplace=True)\n",
    "\n",
    "# I will drop several of the Davenport columns, and rename the ones I keep\n",
    "davenport_keep_cols = {'HS_CEEB':'HS_CEEB',\n",
    "                       'NCESSCH':'HS_NCES',\n",
    "                       'HS_CITY':'HS_CITY',\n",
    "                       'HS_NAME':'MATCH_NAME',\n",
    "                       'HS_ZIP':'HS_POSTAL_CD',\n",
    "                       'HS_STATE':'HS_STATE'}\n",
    "\n",
    "davenport_cross.rename(columns=davenport_keep_cols,inplace=True)\n",
    "\n",
    "# some Davenport crosswalk members were missing an NCES or CEEB code, drop those here\n",
    "ucb_cross = davenport_cross[list(davenport_keep_cols.values())].dropna(subset=['HS_NCES','HS_CEEB'])\n",
    "\n",
    "# match the names which CU Boulder has for each school to the Davenport name (renamed to `match_name`)\n",
    "ucb_cross = ucb_cross.merge(hs_df[['HS_CEEB','HS_NAME']],on='HS_CEEB',how='left')\n",
    "\n",
    "# determine which CEEBs have been matched through the Davenport crosswalk and drop them from `hs_df`\n",
    "matched_ceebs = set(ucb_cross.HS_CEEB)\n",
    "hs_df_less_davenport = hs_df.loc[[_ not in matched_ceebs for _ in hs_df.HS_CEEB]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging in the NCES PSS \n",
    "I will now merge the NCES' [Private School Universe Survey](https://nces.ed.gov/surveys/pss/pssdata.asp) (PSS) into the crosswalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pss_df = pd.read_csv(path.join(DATA_DIR,'nces_pss1718.csv'),dtype=str) \n",
    "# this dataset contains quite a large amount of columns, for now let's take only a small subset \n",
    "pss_cols = ['PPIN','PINST','PADDRS','PCITY','PSTABB','PZIP','PL_CIT','PL_ZIP']\n",
    "pss_df = pss_df[pss_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to search through the PSS for schools in the HS dataset which aren't already contained in the Davenport crosswalk. First I will search for the HS's ZIP code in the PSS dataset. Then I'm going fuzzy match the HS name whose CEEB code we want to match against those which share its ZIP code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little utility script to clean up a schoolname and remove irrelevant text\n",
    "def name_clean(name):\n",
    "    name = name.lower()\n",
    "    name = name.replace('high school','') # leaving \"high school\" in the school name increases apparent match for no reason  \n",
    "    name = name.replace('school','') # ditto\n",
    "    name = name.replace('academy','') # ditto\n",
    "    \n",
    "    return(name.strip())\n",
    "\n",
    "# clean and compare two school names\n",
    "def hs_name_match_score(name1,name2):\n",
    "    return(fuzz.ratio(name_clean(name1),name_clean(name2)))\n",
    "\n",
    "# rewrite `len()` to handle `np.nan`s\n",
    "def myLen(x):\n",
    "    if type(x)==str:\n",
    "        return(len(x))\n",
    "    else:\n",
    "        return(np.nan)\n",
    "\n",
    "hs_df_less_davenport = hs_df_less_davenport.assign(HS_POSTAL_CD=[str(_)[:5] for _ in hs_df_less_davenport.HS_POSTAL_CD])\n",
    "hs_df_less_davenport.replace({'nan':np.nan},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may take a few minutes to run  \n",
    "match_cutoff = 70\n",
    "\n",
    "pss_matches = []\n",
    "for i in range(hs_df_less_davenport.shape[0]):\n",
    "    row = hs_df_less_davenport.iloc[[i]]\n",
    "    \n",
    "    zip_match = (pss_df.PZIP==row.HS_POSTAL_CD.item()) | (pss_df.PL_ZIP==row.HS_POSTAL_CD.item()) \n",
    "    scores = [hs_name_match_score(_,row.HS_NAME.item()) for _ in pss_df.loc[zip_match].PINST]\n",
    "    \n",
    "    try:\n",
    "        match = pss_df.loc[zip_match].iloc[[np.argmax(scores)]]\n",
    "    \n",
    "        if np.max(scores)>match_cutoff:\n",
    "            ret_row = {'HS_NAME': row.HS_NAME.item(),\n",
    "                       'HS_CEEB': row.HS_CEEB.item(),\n",
    "                       'HS_NCES': match.PPIN.item(),\n",
    "                       'MATCH_NAME': match.PINST.item(),\n",
    "                       'MATCH_SCORE': np.max(scores)}\n",
    "                        \n",
    "            pss_matches.append(ret_row)\n",
    "\n",
    "        else:\n",
    "            ret_row = {'HS_NAME': row.HS_NAME.item(),\n",
    "                       'HS_CEEB': row.HS_CEEB.item(),\n",
    "                       'HS_NCES': None,\n",
    "                       'MATCH_NAME': None,\n",
    "                       'MATCH_SCORE': None}\n",
    "    except:\n",
    "        ret_row = {'HS_NAME': row.HS_NAME.item(),\n",
    "                   'HS_CEEB': row.HS_CEEB.item(),\n",
    "                   'HS_NCES': None,\n",
    "                   'MATCH_NAME': None,\n",
    "                   'MATCH_SCORE': None} \n",
    "\n",
    "pss_matches.append(ret_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now add the new PSS crosswalk data into `ucb_cross`, and update the outstanding HS records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pss_cross = pd.DataFrame(pss_matches).replace('None',np.nan).dropna()\n",
    "pss_cross = hs_df_less_davenport.merge(pss_cross[['HS_CEEB','HS_NCES','MATCH_NAME','MATCH_SCORE']],on='HS_CEEB').drop_duplicates() \n",
    "\n",
    "ucb_cross = pd.concat([ucb_cross,pss_cross]).drop_duplicates()\n",
    "\n",
    "matched_ceebs = set(ucb_cross.HS_CEEB)\n",
    "hs_df_less_davenport_pss = hs_df.loc[[_ not in matched_ceebs for _ in hs_df.HS_CEEB]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging in the NCES CCD \n",
    "Now let's try and use the Urban Institute's NCES Common Core of Data (CCD) directory [API](https://educationdata-stg.urban.org/documentation/index.html) to get the remaining NCES codes. I'll use a similar approach as with the PSS data: first narrowing the field to schools sharing a ZIP code, followed by fuzzy string matching on names. First define some functions to handle the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Urban Institute API uses a paged format which returns only\n",
    "# 1000 records at a time, plus a link to the next \"page\". Therefore I wrote this little utility functiion\n",
    "# to run through all the \"pages\" and collect the results, starting at a specified `url` \n",
    "def url_get(url):\n",
    "    with urlopen(url) as f:\n",
    "        response = json.loads(f.read())\n",
    "\n",
    "    count = response['count']\n",
    "\n",
    "    data = []\n",
    "    data += response['results']\n",
    "\n",
    "    while len(data)<count:\n",
    "        nextURL = response['next']\n",
    "\n",
    "        with urlopen(nextURL) as f:\n",
    "            reponse = json.loads(f.read())\n",
    "\n",
    "        data += response['results']\n",
    "\n",
    "    return(data)\n",
    "\n",
    "# look up schools within a certain ZIP code in the NCES' \"Common Core of Data\" (CCD)\n",
    "# year is also a variable, but I believe that later years are roughly supersets of earlier years\n",
    "# so it's advised to just use the most recent year for which data is available\n",
    "def ccd_directory_state_lookup(year,state):\n",
    "    url = f\"https://educationdata-stg.urban.org/api/v1/schools/ccd/directory/{year}/?state_location={state}\"\n",
    "    data_location = url_get(url)    \n",
    "    \n",
    "    return(pd.DataFrame(data_location))\n",
    "\n",
    "def ccd_directory_zip_state_lookup(year,zipcode,state):\n",
    "    data = cd_directory_state_lookup(year,state)\n",
    "    zip_matches = (data.zip_location=='01720') | (data.zip_mailing=='01720')\n",
    "    return(data.loc[zip_matches])\n",
    "    \n",
    "# Takes a row of the HS dataset, pulls down CCD records from Urban Institute (UI) API with the same ZIP code\n",
    "# and fuzzy matches the returned names against the row's HS name\n",
    "def ui_row_match(row,match_cutoff=match_cutoff):  \n",
    "    cands = ccd_directory_zip_lookup(2018,row.HS_POSTAL_CD.item())\n",
    "    \n",
    "    \n",
    "    if cands.shape[0]>0:\n",
    "        scores = [hs_name_match_score(_,row.HS_NAME.item()) for _ in cands.school_name]\n",
    "    \n",
    "        match = cands.iloc[[np.argmax(scores)]]\n",
    "    \n",
    "        if np.max(scores) > match_cutoff:\n",
    "            ret_row = {'HS_NAME': row.HS_NAME.item(),\n",
    "                       'HS_CEEB': row.HS_CEEB.item(),\n",
    "                       'HS_NCES': match.ncessch.item(),\n",
    "                       'MATCH_NAME': match.school_name.item(),\n",
    "                       'MATCH_SCORE': np.max(scores)}\n",
    "        else:\n",
    "            ret_row = {'HS_NAME': row.HS_NAME.item(),\n",
    "                       'HS_CEEB': row.HS_CEEB.item(),\n",
    "                       'HS_NCES': None,\n",
    "                       'MATCH_NAME': None,\n",
    "                       'MATCH_SCORE': None}\n",
    "\n",
    "    else:\n",
    "        ret_row = {'HS_NAME': row.HS_NAME.item(),\n",
    "                   'HS_CEEB': row.HS_CEEB.item(),\n",
    "                   'HS_NCES': None,\n",
    "                   'MATCH_NAME': None,\n",
    "                   'MATCH_SCORE': None}  \n",
    "    return(ret_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now actually perform the API lookups. Because this takes a few hours, pre-saved results are saved and made available with the GitHub repo. The cell will default to the pre-saved results if they are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: UrbanInstitute API appears to no longer filter on ZIP code and this cell will therefore hang if pre-saved results are not available\n",
    "\n",
    "save_fname = path.join(DATA_DIR,'presaved_ccd_match_df.csv')\n",
    "if path.isfile(save_fname):\n",
    "    ccd_colnames = {'hs_name':'HS_NAME',\n",
    "                    'hs_ceeb':'HS_CEEB',\n",
    "                    'ccd_name':'MATCH_NAME',\n",
    "                    'ccd_nces':'HS_NCES',\n",
    "                    'score':'MATCH_SCORE'}\n",
    "\n",
    "    ccd_match_df = pd.read_csv(save_fname,dtype={'hs_ceeb':str,'ccd_nces':str}).drop(columns=['Unnamed: 0'],axis=1).rename(columns=ccd_colnames)\n",
    "\n",
    "else:\n",
    "    # WARNING: this may take a long time to run, pre-saved results can be loaded in the cell below \n",
    "    ccd_matches = []\n",
    "    print('Unmatched HS records remaining:')\n",
    "    print(hs_df_less_davenport_pss.shape[0])\n",
    "    for i in range(hs_df_less_davenport_pss.shape[0]):\n",
    "        row = hs_df_less_davenport_pss.iloc[[i]]\n",
    "        if i%50==0:\n",
    "            with open(path.join(DATA_DIR,'ccd_matches_inprog.p'),'wb') as f:\n",
    "                p.dump(ccd_matches,f)\n",
    "            print(i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if row.HS_POSTAL_CD.item()==None:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                ccd_matches.append(ui_row_match(row))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    ccd_match_df = pd.DataFrame(ccd_matches).replace('None',np.nan)\n",
    "    ccd_match_df.to_csv(path.join(DATA_DIR,'ccd_match_df.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_cross = ccd_match_df.replace('None',np.nan).dropna()\n",
    "ccd_cross = hs_df_less_davenport_pss.merge(ccd_cross[['HS_CEEB','HS_NCES','MATCH_NAME','MATCH_SCORE']],on='HS_CEEB').drop_duplicates() \n",
    "\n",
    "ccd_cross.head()\n",
    "ucb_cross = pd.concat([ucb_cross,ccd_cross]).drop_duplicates()\n",
    "\n",
    "matched_ceebs = set(ucb_cross.HS_CEEB)\n",
    "hs_df_outstanding = hs_df.loc[[_ not in matched_ceebs for _ in hs_df.HS_CEEB]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Match Quality\n",
    "Now let's do some sanity checks of match quality. First I'll overwrite the `MATCH_SCORE` column (which previously only had values for rows come from the PSS or CCD datasets) so that it includes entries for every row with a `HS_NAME` and a `MATCH_NAME` (some entries in the Davenport cross walk didn't have names, so these I'll leave the score as `NaN`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of low-scoring matches by match source:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MATCH_SOURCE\n",
       "0    358\n",
       "1     14\n",
       "2     79\n",
       "Name: MATCH_SCORE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def name_check_score(n1,n2):\n",
    "    if pd.isnull(n1) or pd.isnull(n2):\n",
    "        return(np.nan)\n",
    "    \n",
    "    try:\n",
    "        return(hs_name_match_score(str(n1),str(n2)))\n",
    "    \n",
    "    except:\n",
    "        return(np.nan)\n",
    "\n",
    "davenport_ceebs = set(davenport_cross.HS_CEEB)\n",
    "pss_ceebs = set(pss_cross.HS_CEEB)\n",
    "ccd_ceebs = set(ccd_cross.HS_CEEB)\n",
    "\n",
    "def src_check(ceeb):\n",
    "    if ceeb in davenport_ceebs:\n",
    "        return(0) # source 0 means NCES found in Davenport crosswalk\n",
    "    \n",
    "    elif ceeb in pss_ceebs:\n",
    "        return(1) # source 1 means NCES found in PSS\n",
    "    \n",
    "    elif ceeb in ccd_ceebs:\n",
    "        return(2) # source 2 means NCES found in CCD (the dataset behind the Urban Inst API)\n",
    "    \n",
    "    else:\n",
    "        return(-1) # source -1 means NCES not found yet\n",
    "    \n",
    "\n",
    "ucb_cross['MATCH_SOURCE'] = [src_check(_) for _ in ucb_cross.HS_CEEB]\n",
    "ucb_cross['MATCH_SCORE'] = [name_check_score(n1,n2) for n1,n2 in zip(ucb_cross.HS_NAME, ucb_cross.MATCH_NAME) ]\n",
    "\n",
    "print('Number of low-scoring matches by match source:')\n",
    "ucb_cross.groupby('MATCH_SOURCE').MATCH_SCORE.apply(lambda x: sum(x < match_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There do appear to be some rows from the PSS and CCD datasets with match scores below the cut-off threshold I previously assigned. However, closer inspection reveals that many of these all duplicates of another entry with a higher match score. Although the original `hs_df` dataset had been previously de-duplicated, there are still around 60 CEEB codes which appear more than once in the crosswalk. This might be due to typos in school names, errors/inconsitent ZIP codes (eg. mailing vs. location), etc. Additionally, HS names may change over time, but will retain their CEEB code. When I merged on CEEB codes, duplicated codes were matched with names which are possibly different than what was indicated in the original dataset.\n",
    "\n",
    "Therefore I'm going to create a column indicating if a CEEB code is duped somewhere else in the dataset. For schools which were matched via that PSS or CCD datasets, these duplicated cases are the cause of several seemingly \"low-quality\" school matches. Because I pulled the most recent available versions of both the PSS and CCD datasets, I'm going to assume that their provided names are the correct/updated ones and overwrite the `HS_NAME` column wherever a record was duped, and the data source is PSS or CCD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HS records with a duped CEEB:\n",
      "140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MATCH_SOURCE  HS_DUPED\n",
       "0             False       341\n",
       "              True         17\n",
       "1             False         0\n",
       "              True         14\n",
       "2             False        66\n",
       "              True         13\n",
       "Name: MATCH_SCORE, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceeb_cts = ucb_cross.groupby('HS_CEEB').count()\n",
    "ceeb_cts['HS_CEEB'] = ceeb_cts.index\n",
    "ceeb_dupes = ceeb_cts.HS_CEEB.loc[ceeb_cts.HS_NAME>1]\n",
    "\n",
    "ucb_cross['HS_DUPED'] = [_ in ceeb_dupes for _ in ucb_cross.HS_CEEB]\n",
    "print('Number of HS records with a duped CEEB:')\n",
    "print(np.sum(ucb_cross.HS_DUPED))\n",
    "\n",
    "ucb_cross.groupby(['MATCH_SOURCE','HS_DUPED']).MATCH_SCORE.apply(lambda x: sum(x < match_cutoff))\n",
    "#low_qual = list(ucb_cross.MATCH_SCORE<match_cutoff)\n",
    "#src_pss_ccd = ([_ in [1,2] for _ in ucb_cross.MATCH_SOURCE])\n",
    "#ucb_cross.loc[src_pss_ccd & ucb_cross.HS_DUPED].sort_values(['MATCH_SCORE'])\n",
    "\n",
    "#ucb_cross.HS_NAME.replace([a and b for a,b in zip(src_pss_ccd, ucb_cross.HS_DUPED)], ucb_cross.MATCH_NAME, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb_cross['MATCH_SCORE'] = [name_check_score(n1,n2) for n1,n2 in zip(ucb_cross.HS_NAME, ucb_cross.MATCH_NAME) ]\n",
    "\n",
    "foo = ucb_cross.drop_duplicates(subset=['HS_CEEB'])\n",
    "print('Number of low-scoring matches')\n",
    "print( 'From PSS+CCD: {num}'.format(num=np.sum( [(sco<match_cutoff) and (src!=2) for sco,src in zip(foo.MATCH_SCORE,foo.MATCH_SOURCE)] ) ) )\n",
    "print( 'From Davenport: {num}'.format(num=np.sum( [(sco<match_cutoff) and (src==2) for sco,src in zip(foo.MATCH_SCORE,foo.MATCH_SOURCE)] ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the low-quality matches coming from the Davenport crosswalk. It appears as though there are considerably more. I'm going to trust Davenport for the data quality here (at least, compared to the high school names entered on to college applications as they tend to be full over abbreviations and typos). As before I'll overwrite the `HS_NAME` with the `MATCH_NAME` column, and then I'll drop all duplications of `HS_CEEB` and `HS_NCES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_davenport = (ucb_cross.MATCH_SOURCE == 0)\n",
    "print('Number of duplications where source data is the Davenport crosswalk:')\n",
    "print(ucb_cross.loc[low_qual & src_davenport].shape[0])\n",
    "\n",
    "ucb_cross.HS_NAME.replace([a and b for a,b in zip(src_davenport, list(ucb_cross.HS_DUPED))], ucb_cross.MATCH_NAME, inplace=True)\n",
    "\n",
    "ucb_cross = ucb_cross.drop_duplicates(subset=['HS_CEEB','HS_NCES']) \n",
    "ucb_cross.drop(columns=['HS_DUPED'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTurk Completion\n",
    "We've now used up all of our \"nice\" datasets which would allow for automated matching. At this point we'll move the rest over to MTurk. The code below collects and  merges the responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resp_clean(x):\n",
    "    x = str(x)\n",
    "    if 'NCES School ID: ' in x:\n",
    "        x = x.split('NCES School ID: ')\n",
    "        return(x[-1])\n",
    "    \n",
    "    elif ' ' in x:\n",
    "        return('NA')\n",
    "    \n",
    "    elif 'grade' in x.lower():\n",
    "        return('NA')\n",
    "    \n",
    "    else:\n",
    "        return(x)\n",
    "\n",
    "def resp_agg(x):\n",
    "    votes = x.value_counts()\n",
    "    if np.max(votes) > np.sum(votes)/2.:\n",
    "        return(votes.idxmax())\n",
    "    \n",
    "    else:\n",
    "        nces = np.argmax([len(_) for _ in votes.index])\n",
    "        return('NA')\n",
    "\n",
    "results = pd.read_csv(path.join(MTURK_DIR,'mturk_results_v3_graded.csv'))\n",
    "results = results.loc[results.Approve=='x']\n",
    "results.replace(' ', np.nan, inplace=True)\n",
    "\n",
    "results['Answer'] = results['Answer.HS_NCES'] \n",
    "results['Answer'].loc[results['Answer.HS_NO_NCES.on']] = 'NA'\n",
    "\n",
    "resps_full = results[['WorkerId','Answer','Input.HS_NAME','Input.HS_CEEB']].rename(columns={'Input.HS_NAME':'HS_NAME','Input.HS_CEEB':'HS_CEEB'})\n",
    "resps_full['Answer'] = resps_full.Answer.apply(resp_clean)\n",
    "resps_pivot = resps_full.pivot_table(index='HS_CEEB',values='Answer',columns='WorkerId', aggfunc = lambda x: x)\n",
    "\n",
    "max_width = 4\n",
    "resps = []\n",
    "for i in range(resps_pivot.shape[0]):\n",
    "    row = resps_pivot.iloc[i]\n",
    "    ceeb = resps_pivot.index[i]\n",
    "    row = list(row.loc[pd.notnull(row)])\n",
    "    \n",
    "    while len(row)<max_width:\n",
    "        row += [np.nan]\n",
    "    \n",
    "    resp_row = {f'resp_{i}':resp for i,resp in zip(range(max_width),row)}\n",
    "    resp_row['HS_CEEB'] = str(ceeb)\n",
    "    \n",
    "    resps.append(resp_row)\n",
    "    \n",
    "resps = pd.DataFrame(resps) \n",
    "resps['HS_NCES'] = [resp_agg(resps.iloc[i,:4]) for i in range(resps.shape[0])] \n",
    "name_ceeb_df = resps_full[['HS_CEEB','HS_NAME']].drop_duplicates()\n",
    "resps = resps.merge(name_ceeb_df, on='HS_CEEB')\n",
    "\n",
    "resps[['HS_NAME','HS_CEEB','HS_NCES']].to_csv(path.join(DATA_DIR,'mturk_crosswalk.csv'),index=False)\n",
    "\n",
    "mturk_cross = resps[['HS_NAME','HS_CEEB','HS_NCES']]\n",
    "\n",
    "#my_cross = my_cross.append(mturk_crosswalk.rename(columns={'HS_NAME':'HS_MATCH_NAME'}))\n",
    "\n",
    "#us_hs_ceebs = set(us_hs_df.HS_CEEB) \n",
    "#us_hs_df_complete = us_hs_df_complete.append(mturk_crosswalk.loc[[_ in us_hs_ceebs for _ in mturk_crosswalk.HS_CEEB]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the MTurk responses\n",
    "mturk_cross = mturk_cross.replace('NA',np.nan).dropna(subset=['HS_NCES'])\n",
    "mturk_cross = hs_df_outstanding.merge(mturk_cross.rename(columns={'HS_NAME':'MATCH_NAME'})[['HS_CEEB','HS_NCES','MATCH_NAME']],on='HS_CEEB').drop_duplicates() \n",
    "\n",
    "ucb_cross = pd.concat([ucb_cross,mturk_cross]).drop_duplicates()\n",
    "\n",
    "matched_ceebs = set(ucb_cross.HS_CEEB)\n",
    "hs_df_outstanding = hs_df.loc[[_ not in matched_ceebs for _ in hs_df.HS_CEEB]]\n",
    "\n",
    " hs_df_outstanding.to_csv(path.join(MTURK_DIR,'outstanding_hs.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data for second HiT and export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Crosswalk\n",
    "I'm going to export two datasets. The first is the best crosswalk data we have: this will be a concatentation of the Davenport crosswalk with the data I pulled from the PSS and CCD (the `my_cross` dataframe) plus the MTurk responses. This will be for future release or development. However, because there are a lot more schools in there than are listed in the First Year data I'll also return a left join of that crosswalk with the `us_hs_df` data (the `us_hs_df_complete` dataframe). This data will then be augmented by census data, NCES data, etc. Both of these exported dataframes will have the same structure, so if I decide to just augment the larger data in the future it should be a trivial tweak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Davenport crosswalk size:')\n",
    "print(davenport_cross.shape)\n",
    "print('Augmented crosswalk size:')\n",
    "print(ucb_cross.shape)\n",
    "print('Growth as percent of original size:')\n",
    "p = ucb_cross.shape[0] - davenport_cross.shape[0]\n",
    "p /= davenport_cross.shape[0]  \n",
    "print(str(round(100*p))+'%')\n",
    "\n",
    "ucb_cross.to_csv(path.join(PROJ_DIR,'oda_nces_ceeb_crosswalk.csv'),index=False)\n",
    "\n",
    "ucb_ceebs = set(hs_df.HS_CEEB)\n",
    "ucb_cross.loc[[_ in ucb_ceebs for _ in ucb_cross.HS_CEEB]].to_csv(path.join(DATA_DIR,'oda_nces_ceeb_crosswalk_cuboulder_only.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
